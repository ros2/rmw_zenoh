// Copyright 2023 Open Source Robotics Foundation, Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#ifndef DETAIL__RMW_DATA_TYPES_HPP_
#define DETAIL__RMW_DATA_TYPES_HPP_

#include <zenoh.h>

#include <condition_variable>
#include <deque>
#include <memory>
#include <mutex>
#include <optional>
#include <string>
#include <unordered_map>
#include <utility>
#include <variant>
#include <vector>

#include "rcutils/allocator.h"

#include "rmw/rmw.h"

#include "rosidl_runtime_c/type_hash.h"

#include "event.hpp"
#include "graph_cache.hpp"
#include "message_type_support.hpp"
#include "rmw_wait_set_data.hpp"
#include "service_type_support.hpp"

/// Structs for various type erased data fields.

///=============================================================================
class rmw_context_impl_s final
{
public:
  // Enclave, name used to find security artifacts in a sros2 keystore.
  char * enclave;

  // An owned session.
  z_owned_session_t session;

  // An optional SHM manager that is initialized of SHM is enabled in the
  // zenoh session config.
  std::optional<zc_owned_shm_manager_t> shm_manager;

  z_owned_subscriber_t graph_subscriber;

  /// Shutdown flag.
  bool is_shutdown;

  // Equivalent to rmw_dds_common::Context's guard condition
  /// Guard condition that should be triggered when the graph changes.
  rmw_guard_condition_t * graph_guard_condition;

  std::unique_ptr<rmw_zenoh_cpp::GraphCache> graph_cache;

  size_t get_next_entity_id();

private:
  // A counter to assign a local id for every entity created in this session.
  size_t next_entity_id_{0};
};

namespace rmw_zenoh_cpp
{
///=============================================================================
struct rmw_node_data_t
{
  // The Entity generated for the node.
  std::shared_ptr<liveliness::Entity> entity;

  // Liveliness token for the node.
  zc_owned_liveliness_token_t token;

  // The entity id of this node as generated by get_next_entity_id().
  // Every interface created by this node will include this id in its liveliness token.
  size_t id;
};

///=============================================================================
class rmw_publisher_data_t final
{
public:
  // The Entity generated for the publisher.
  std::shared_ptr<liveliness::Entity> entity;

  // An owned publisher.
  z_owned_publisher_t pub;

  // Optional publication cache when durability is transient_local.
  std::optional<ze_owned_publication_cache_t> pub_cache;

  // Store the actual QoS profile used to configure this publisher.
  rmw_qos_profile_t adapted_qos_profile;

  // Liveliness token for the publisher.
  zc_owned_liveliness_token_t token;

  // Type support fields
  const void * type_support_impl;
  const char * typesupport_identifier;
  const rosidl_type_hash_t * type_hash;
  MessageTypeSupport * type_support;

  // Context for memory allocation for messages.
  rmw_context_t * context;

  uint8_t pub_gid[RMW_GID_STORAGE_SIZE];

  size_t get_next_sequence_number();

  EventsManager events_mgr;

private:
  std::mutex sequence_number_mutex_;
  size_t sequence_number_{1};
};

///=============================================================================
// z_owned_closure_sample_t
void sub_data_handler(const z_sample_t * sample, void * sub_data);

struct saved_msg_data
{
  explicit saved_msg_data(
    zc_owned_payload_t p,
    uint64_t recv_ts,
    const uint8_t pub_gid[RMW_GID_STORAGE_SIZE],
    int64_t seqnum,
    int64_t source_ts);

  ~saved_msg_data();

  zc_owned_payload_t payload;
  uint64_t recv_timestamp;
  uint8_t publisher_gid[RMW_GID_STORAGE_SIZE];
  int64_t sequence_number;
  int64_t source_timestamp;
};

///=============================================================================
class rmw_subscription_data_t final
{
public:
  // The Entity generated for the subscription.
  std::shared_ptr<liveliness::Entity> entity;

  // An owned subscriber or querying_subscriber depending on the QoS settings.
  std::variant<z_owned_subscriber_t, ze_owned_querying_subscriber_t> sub;

  // Store the actual QoS profile used to configure this subscription.
  rmw_qos_profile_t adapted_qos_profile;

  // Liveliness token for the subscription.
  zc_owned_liveliness_token_t token;

  const void * type_support_impl;
  const char * typesupport_identifier;
  const rosidl_type_hash_t * type_hash;
  MessageTypeSupport * type_support;
  rmw_context_t * context;

  bool queue_has_data_and_attach_condition_if_not(rmw_wait_set_data_t * wait_set_data);

  bool detach_condition_and_queue_is_empty();

  std::unique_ptr<saved_msg_data> pop_next_message();

  void add_new_message(std::unique_ptr<saved_msg_data> msg, const std::string & topic_name);

  DataCallbackManager data_callback_mgr;
  EventsManager events_mgr;

private:
  std::deque<std::unique_ptr<saved_msg_data>> message_queue_;
  mutable std::mutex message_queue_mutex_;

  // Map GID of a publisher to the sequence number of the message it published.
  std::unordered_map<size_t, int64_t> last_known_published_msg_;
  size_t total_messages_lost_{0};

  void notify();

  rmw_wait_set_data_t * wait_set_data_{nullptr};
  std::mutex condition_mutex_;
};


///=============================================================================
void service_data_handler(const z_query_t * query, void * service_data);

///=============================================================================
void client_data_handler(z_owned_reply_t * reply, void * client_data);
void client_data_drop(void * data);

///=============================================================================
class ZenohQuery final
{
public:
  ZenohQuery(const z_query_t * query);

  ~ZenohQuery();

  const z_query_t get_query() const;

private:
  z_owned_query_t query_;
};

///=============================================================================
class rmw_service_data_t final
{
public:
  // The Entity generated for the service.
  std::shared_ptr<liveliness::Entity> entity;

  z_owned_keyexpr_t keyexpr;
  z_owned_queryable_t qable;

  // Store the actual QoS profile used to configure this service.
  // The QoS is reused for getting requests and sending responses.
  rmw_qos_profile_t adapted_qos_profile;

  // Liveliness token for the service.
  zc_owned_liveliness_token_t token;

  const void * request_type_support_impl;
  const void * response_type_support_impl;
  const char * typesupport_identifier;
  const rosidl_type_hash_t * type_hash;
  RequestTypeSupport * request_type_support;
  ResponseTypeSupport * response_type_support;

  rmw_context_t * context;

  bool queue_has_data_and_attach_condition_if_not(rmw_wait_set_data_t * wait_set_data);

  bool detach_condition_and_queue_is_empty();

  std::unique_ptr<ZenohQuery> pop_next_query();

  void add_new_query(std::unique_ptr<ZenohQuery> query);

  bool add_to_query_map(const rmw_request_id_t & request_id, std::unique_ptr<ZenohQuery> query);

  std::unique_ptr<ZenohQuery> take_from_query_map(const rmw_request_id_t & request_id);

  DataCallbackManager data_callback_mgr;

private:
  void notify();

  // Deque to store the queries in the order they arrive.
  std::deque<std::unique_ptr<ZenohQuery>> query_queue_;
  mutable std::mutex query_queue_mutex_;

  // Map to store the sequence_number (as given by the client) -> ZenohQuery
  using SequenceToQuery = std::unordered_map<int64_t, std::unique_ptr<ZenohQuery>>;
  std::unordered_map<size_t, SequenceToQuery> sequence_to_query_map_;
  std::mutex sequence_to_query_map_mutex_;

  rmw_wait_set_data_t * wait_set_data_{nullptr};
  std::mutex condition_mutex_;
};

///=============================================================================
class ZenohReply final
{
public:
  ZenohReply(const z_owned_reply_t * reply);

  ~ZenohReply();

  std::optional<z_sample_t> get_sample() const;

private:
  z_owned_reply_t reply_;
};

///=============================================================================
class rmw_client_data_t final
{
public:
  // The Entity generated for the client.
  std::shared_ptr<liveliness::Entity> entity;

  z_owned_keyexpr_t keyexpr;

  // Store the actual QoS profile used to configure this client.
  // The QoS is reused for sending requests and getting responses.
  rmw_qos_profile_t adapted_qos_profile;

  // Liveliness token for the client.
  zc_owned_liveliness_token_t token;

  const void * request_type_support_impl;
  const void * response_type_support_impl;
  const char * typesupport_identifier;
  const rosidl_type_hash_t * type_hash;
  RequestTypeSupport * request_type_support;
  ResponseTypeSupport * response_type_support;

  rmw_context_t * context;

  uint8_t client_gid[RMW_GID_STORAGE_SIZE];

  size_t get_next_sequence_number();

  void add_new_reply(std::unique_ptr<rmw_zenoh_cpp::ZenohReply> reply);

  bool queue_has_data_and_attach_condition_if_not(rmw_wait_set_data_t * wait_set_data);

  bool detach_condition_and_queue_is_empty();

  std::unique_ptr<rmw_zenoh_cpp::ZenohReply> pop_next_reply();

  DataCallbackManager data_callback_mgr;

  // See the comment for "num_in_flight" below on the use of this method.
  void increment_in_flight_callbacks();

  // See the comment for "num_in_flight" below on the use of this method.
  bool shutdown_and_query_in_flight();

  // See the comment for "num_in_flight" below on the use of this method.
  bool decrement_queries_in_flight_and_is_shutdown(bool & queries_in_flight);

  bool is_shutdown() const;

private:
  void notify();

  size_t sequence_number_{1};
  std::mutex sequence_number_mutex_;

  rmw_wait_set_data_t * wait_set_data_{nullptr};
  std::mutex condition_mutex_;

  std::deque<std::unique_ptr<rmw_zenoh_cpp::ZenohReply>> reply_queue_;
  mutable std::mutex reply_queue_mutex_;

  // rmw_zenoh uses Zenoh queries to implement clients.  It turns out that in Zenoh, there is no
  // way to cancel a query once it is in-flight via the z_get() zenoh-c API. Thus, if an
  // rmw_zenoh_cpp user does rmw_create_client(), rmw_send_request(), rmw_destroy_client(), but the
  // query comes in after the rmw_destroy_client(), rmw_zenoh_cpp could access already-freed memory.
  //
  // The next 3 variables are used to avoid that situation.  Any time a query is initiated via
  // rmw_send_request(), num_in_flight_ is incremented.  When the Zenoh calls the callback for the
  // query reply, num_in_flight_ is decremented.  When rmw_destroy_client() is called, is_shutdown_
  // is set to true.  If num_in_flight_ is 0, the data associated with this structure is freed.
  // If num_in_flight_ is *not* 0, then the data associated with this structure is maintained.
  // In the situation where is_shutdown_ is true, and num_in_flight_ drops to 0 in the query
  // callback, the query callback will free up the structure.
  //
  // There is one case which is not handled by this, which has to do with timeouts.  The query
  // timeout is currently set to essentially infinite.  Thus, if a query is in-flight but never
  // returns, the memory in this structure will never be freed.  There isn't much we can do about
  // that at this time, but we may want to consider changing the timeout so that the memory can
  // eventually be freed up.
  mutable std::mutex in_flight_mutex_;
  bool is_shutdown_{false};
  size_t num_in_flight_{0};
};

///=============================================================================
template<typename T, typename H>
T make_z_closure(void * context, void (*call)(H *, void *), void (*drop)(void *))
{
  T closure;
  closure.context = context;
  closure.call = call;
  closure.drop = drop;
  return closure;
}
}  // namespace rmw_zenoh_cpp

#endif  // DETAIL__RMW_DATA_TYPES_HPP_
